{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This password evaluator is a support function to be used in the project of fit5120/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Data Visulization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#For Modelling and evaluation\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, cross_val_score,KFold\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier,StackingClassifier,BaggingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#For text preprocessing\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#For model parameter saving and loading\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('data.csv',on_bad_lines='skip') #ignore badline from dataset\n",
    "df.isna().sum()\n",
    "df.duplicated().sum()\n",
    "#only 1 missing value, and no duplicate found,will drop the bad record directly\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import text data for all the weak passwords from rock you leak\n",
    "df2 = pd.read_csv('rockyou.txt',delimiter='\\t',header = None, names = ['password'],encoding='ISO-8859-1')\n",
    "df2.dropna(inplace = True)\n",
    "df2.drop_duplicates(inplace = True)\n",
    "df2['strength'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                password  strength\n",
      "0                 wwf598         0\n",
      "1                tommy93         0\n",
      "2                menelg1         0\n",
      "3                 kenar1         0\n",
      "4                xj66dkv         0\n",
      "...                  ...       ...\n",
      "249406  ZEmAYPzQxMggt8VF         2\n",
      "249407  zrF8CLTgyNAkiC0p         2\n",
      "249408  gcrM80zcyNQXMGGq         2\n",
      "249409  tE1QyfTAzMQ2C2pu         2\n",
      "249410    550AjApYMoqAqy         2\n",
      "\n",
      "[249411 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.concat([df,df2],ignore_index=True)\n",
    "\n",
    "# Compute the value counts of the Gender column\n",
    "value_counts = df_full['strength'].value_counts()\n",
    "\n",
    "# Set the number of samples to be drawn from each group\n",
    "n_samples = value_counts.min()\n",
    "\n",
    "# Group the dataframe by Gender and sample n_samples from each group\n",
    "sampled_df = df.groupby('strength').apply(lambda x: x.sample(n=n_samples)).reset_index(drop=True)\n",
    "\n",
    "# Print the sampled dataframe\n",
    "print(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    0\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanli/miniforge3/envs/ds/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = sampled_df['password']\n",
    "y = sampled_df['strength']\n",
    "#tokenize password\n",
    "def word_to_char(word):\n",
    "    return list(word)\n",
    "vectorizer = TfidfVectorizer(tokenizer=word_to_char)\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "def train_val_test_split(X,y,ratio):\n",
    "    X_train,X_,y_train,y_ = train_test_split(X,y,test_size=ratio,stratify=y,random_state=1)\n",
    "    X_val,X_test,y_val,y_test = train_test_split(X_,y_,test_size=.5,stratify=y_,random_state=1)\n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test_split(X,y,ratio=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Performance:\n",
      "\n",
      "Random forest: 0.9442035681894781\n",
      "Bagging: 0.9219457394123618\n",
      "Xgboost: 0.9810177984098212\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "lgbm: 0.9621568742404788\n"
     ]
    }
   ],
   "source": [
    "#Model training with CV\n",
    "\n",
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending models into the list\n",
    "\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "models.append((\"lgbm\", lgb.LGBMClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "\n",
    "results = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "score = []\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "\n",
    "print(\"\\n\" \"Cross-Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "    )  # Setting number of splits equal to 5\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train, y=y_train, scoring='f1_macro', cv=kfold\n",
    "    )\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Performance:\n",
      "\n",
      "Random forest: 0.999891171571467\n",
      "Bagging: 0.9956067805243928\n",
      "Xgboost: 0.9938909830656067\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "lgbm: 0.9688391856539122\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" \"Training Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = metrics.f1_score(y_train, model.predict(X_train),average='macro')\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Performance:\n",
      "\n",
      "Random forest: 0.9487219579052363\n",
      "Bagging: 0.9246642958210404\n",
      "Xgboost: 0.9821373154455623\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "lgbm: 0.9641671748892238\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = metrics.f1_score(y_val, model.predict(X_val),average='macro')\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'subsample': 0.2, 'n_estimators': 250, 'learning_rate': 0.01, 'gamma': 3} with CV score=0.9028494908952561:\n"
     ]
    }
   ],
   "source": [
    "#Using Xgboost provided the best f1_marco result, thus we can fine tune it\n",
    "# defining model - XGBoost Hyperparameter Tuning\n",
    "model = XGBClassifier(random_state=1, eval_metric=\"logloss\")\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(150, 300, 50),\n",
    "    \"learning_rate\": [0.0001,0.001,0.01],\n",
    "    \"gamma\": [0, 3, 5],\n",
    "    \"subsample\": [0.5, 0.9,0.2],\n",
    "}\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    random_state=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, gamma=3, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=250, n_jobs=0,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, gamma=3, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=250, n_jobs=0,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', feature_types=None, gamma=3, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=250, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto', ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "xgb_tuned = XGBClassifier(\n",
    "**randomized_cv.best_params_,eval_metric = 'logloss',random_state = 1\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "xgb_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9034945949285352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_tuned.predict(X_test)\n",
    "metrics.f1_score(y_test,y_pred,average='macro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040950862724322"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test,y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9034720781264691"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test,y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040949427991019"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open(\"xgb_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgb_tuned, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open(\"xgb_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzde5577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kino3434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visi7k1yr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megzy123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lamborghin1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669635</th>\n",
       "      <td>10redtux10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669636</th>\n",
       "      <td>infrared1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669637</th>\n",
       "      <td>184520socram</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669638</th>\n",
       "      <td>marken22a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669639</th>\n",
       "      <td>fxx4pw4g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669639 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            password  strength\n",
       "0           kzde5577         1\n",
       "1           kino3434         1\n",
       "2          visi7k1yr         1\n",
       "3           megzy123         1\n",
       "4        lamborghin1         1\n",
       "...              ...       ...\n",
       "669635    10redtux10         1\n",
       "669636     infrared1         1\n",
       "669637  184520socram         1\n",
       "669638     marken22a         1\n",
       "669639      fxx4pw4g         1\n",
       "\n",
       "[669639 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77070576, 0.16072197, 0.06857225]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '123456'\n",
    "\n",
    "def word_to_char(word):\n",
    "    return list(word)\n",
    "# Load the vectorizer from the file\n",
    "with open(\"vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "X  = vectorizer.transform([text])\n",
    "y_pred = model.predict_proba(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77070576"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
