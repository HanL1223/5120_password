{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This password evaluator is a support function to be used in the project of fit5120/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Data Visulization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#For Modelling and evaluation\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,StackingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#For text preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#For model parameter saving and loading\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('data.csv',on_bad_lines='skip') #ignore badline from dataset\n",
    "df.isna().sum()\n",
    "df.duplicated().sum()\n",
    "#only 1 missing value, and no duplicate found,will drop the bad record directly\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import text data for all the weak passwords from rock you leak\n",
    "df2 = pd.read_csv('rockyou.txt',delimiter='\\t',header = None, names = ['password'],encoding='ISO-8859-1')\n",
    "df2.dropna(inplace = True)\n",
    "df2.drop_duplicates(inplace = True)\n",
    "df2['strength'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                password  strength\n",
      "0                lipo3ak         0\n",
      "1                 lynd0n         0\n",
      "2                pallek1         0\n",
      "3                qqnanm3         0\n",
      "4                 josh20         0\n",
      "...                  ...       ...\n",
      "249406  JEW7LwjEyMQLnm4h         2\n",
      "249407  N19emMjYwOABRfZZ         2\n",
      "249408   736DOceQoZYxyKy         2\n",
      "249409    418ezEdiRucugy         2\n",
      "249410  0wubFZjU2MgUn8pa         2\n",
      "\n",
      "[249411 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.concat([df,df2],ignore_index=True)\n",
    "\n",
    "# Compute the value counts of the Gender column\n",
    "value_counts = df_full['strength'].value_counts()\n",
    "\n",
    "# Set the number of samples to be drawn from each group\n",
    "n_samples = value_counts.min()\n",
    "\n",
    "# Group the dataframe by Gender and sample n_samples from each group\n",
    "sampled_df = df.groupby('strength').apply(lambda x: x.sample(n=n_samples)).reset_index(drop=True)\n",
    "\n",
    "# Print the sampled dataframe\n",
    "print(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sampled_df['password']\n",
    "y = sampled_df['strength']\n",
    "#tokenize password\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer = 'char')\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "with open(\"vectorizer2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "def train_val_test_split(X,y,ratio):\n",
    "    X_train,X_,y_train,y_ = train_test_split(X,y,test_size=ratio,stratify=y,random_state=1)\n",
    "    X_val,X_test,y_val,y_test = train_test_split(X_,y_,test_size=.5,stratify=y_,random_state=1)\n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test_split(X,y,ratio=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Performance:\n",
      "\n",
      "Random forest: 0.9456721865928752\n",
      "Bagging: 0.9218988232481464\n",
      "Xgboost: 0.9817256899409784\n",
      "lgbm: 0.9635410536172795\n"
     ]
    }
   ],
   "source": [
    "#Model training with CV\n",
    "\n",
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending models into the list\n",
    "\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "models.append((\"lgbm\", lgb.LGBMClassifier(random_state=1)))\n",
    "\n",
    "results = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "score = []\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "\n",
    "print(\"\\n\" \"Cross-Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "    )  # Setting number of splits equal to 5\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train, y=y_train, scoring='f1_macro', cv=kfold\n",
    "    )\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Performance:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" \"Training Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = metrics.f1_score(y_train, model.predict(X_train),average='macro')\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = metrics.f1_score(y_val, model.predict(X_val),average='macro')\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Xgboost provided the best f1_marco result, thus we can fine tune it\n",
    "# defining model - XGBoost Hyperparameter Tuning\n",
    "model = XGBClassifier(random_state=1, eval_metric=\"logloss\")\n",
    "\n",
    "# Parameter grid to pass in RandomizedSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(150, 300, 50),\n",
    "    \"learning_rate\": [0.0001,0.001,0.01,0.0015],\n",
    "    \"gamma\": [0, 3, 5,7],\n",
    "    \"subsample\": [0.5, 0.9,0.2,0.35],\n",
    "    'reg_alpha':[0,1],\n",
    "    'reg_lambda':[0,1]\n",
    "}\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    random_state=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = [('lgbm', lgb.LGBMClassifier(eval_metric='logloss', random_state=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = XGBClassifier(**randomized_cv.best_params_,eval_metric = 'logloss',random_state = 1) #use best performed model as final_model\n",
    "estimator = models #droping XGB and use others as init estimators\n",
    "\n",
    "reg = StackingClassifier(\n",
    "estimators=est,\n",
    "final_estimator=final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the stakeclassifer using validation set\n",
    "reg.fit(X_train,y_train)\n",
    "y_pred = reg.predict(X_val)\n",
    "print(f\"Stacking Method, F1: {metrics.f1_score(y_val,y_pred,average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building model with best parameters\n",
    "xgb_tuned = XGBClassifier(\n",
    "**randomized_cv.best_params_,eval_metric = 'logloss',random_state = 1\n",
    ")\n",
    "# Fit the model on training data\n",
    "xgb_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_tuned.predict(X_test)\n",
    "metrics.f1_score(y_test,y_pred,average='macro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "metrics.f1_score(y_test,y_pred,average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open(\"stack_model4.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open(\"xgb_model2.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'apple123'\n",
    "\n",
    "# Load the vectorizer from the file\n",
    "with open(\"vectorizer2.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "X  = vectorizer.transform([text])\n",
    "y_pred = model.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
